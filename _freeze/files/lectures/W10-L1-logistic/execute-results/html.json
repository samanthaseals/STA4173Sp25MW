{
  "hash": "2372d2ac516dcaa8fda60b5ee7b85ac0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"**Logistic Regression**\"\nsubtitle: \"**STA4173: Biostatistics** <br> Spring 2025\"\nformat: \n  revealjs: \n    code-overflow: wrap\n    df-print: paged\n    embed-resources: true\n    slide-number: true\n    width: 1600\n    height: 900\n    html-math-method: katex\n    theme:\n      - default\nexecute:\n  echo: true\n  warning: false\n  message: false\n  error: true\neditor: source\n---\n\n\n\n## Introduction  \n\n- We have previously discussed continuous outcomes and the normal distribution.\n\n- Let's now consider categorical outcomes:\n\n    - **Binary**\n    \n    - Ordinal\n    \n    - Multinomial\n    \n## Binary Logistic Regression  \n\n- We model binary outcomes using logistic regression,\n\n$$\\ln \\left( \\frac{\\pi}{1-\\pi} \\right) = \\beta_0 + \\beta_1 x_1 + ... + \\beta_k x_k,$$\n\n- where $\\pi = \\text{P}[Y = 1]$ = the probability of the outcome/event.\n\n- How is this different from linear regression?\n\n$$ y = \\beta_0 + \\beta_1 x_1 + ... + \\beta_k x_k $$\n\n## Binary Logistic Regression \n\n- Why isn't linear regression appropriate?\n\n## R Syntax  \n\n- In the [`glm()`](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/glm) function, we specify the binomial [`family`](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/family).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- glm(binary_outcome ~ predictor_1 + predictor_2 + ... + predictor_k, \n         data = dataset_name, \n         family = \"binomial\")\n```\n:::\n\n\n\n## Today's Data  \n\n- Today we will be using the [Roy Kent](https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-09-26/readme.md) dataset from [Tidy Tuesday](https://github.com/rfordatascience/tidytuesday).\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Season\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Episode\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"F_count_RK\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"F_perc\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"dating\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"IMDB\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"1\",\"3\":\"2\",\"4\":\"15.4\",\"5\":\"0\",\"6\":\"0\"},{\"1\":\"1\",\"2\":\"2\",\"3\":\"2\",\"4\":\"25.0\",\"5\":\"0\",\"6\":\"0\"},{\"1\":\"1\",\"2\":\"3\",\"3\":\"7\",\"4\":\"53.8\",\"5\":\"0\",\"6\":\"1\"},{\"1\":\"1\",\"2\":\"4\",\"3\":\"8\",\"4\":\"47.1\",\"5\":\"0\",\"6\":\"0\"},{\"1\":\"1\",\"2\":\"5\",\"3\":\"4\",\"4\":\"30.8\",\"5\":\"0\",\"6\":\"1\"},{\"1\":\"1\",\"2\":\"6\",\"3\":\"2\",\"4\":\"22.2\",\"5\":\"0\",\"6\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n## Example: Roy Kent's F-Bombs  \n\n- Let's model the odds of Roy Kent and Keeley Jones dating in a particular episode (*dating*) as a function of the percentage of F-bombs that belong to Roy Kent (*F_perc*) and if the IMDB rating is an 8.5 or better (*IMDB*).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- glm(dating ~ F_perc + IMDB, \n          data = richmondway, \n          family = \"binomial\"(link=\"logit\"))\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = dating ~ F_perc + IMDB, family = binomial(link = \"logit\"), \n    data = richmondway)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)\n(Intercept) -1.76166    1.08995  -1.616    0.106\nF_perc       0.03323    0.02506   1.326    0.185\nIMDB         0.37986    0.72250   0.526    0.599\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 46.662  on 33  degrees of freedom\nResidual deviance: 44.261  on 31  degrees of freedom\nAIC: 50.261\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n\n\n## Example: Roy Kent's F-Bombs  \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoefficients(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)      F_perc        IMDB \n-1.76166167  0.03323012  0.37986267 \n```\n\n\n:::\n:::\n\n\n\n- The model is as follows,\n\n$$\\ln \\left( \\frac{\\hat{\\pi}}{1-\\hat{\\pi}} \\right) = -1.76 + 0.03 x_1 + 0.38 x_2,$$ \n\n- where \n\n    - $x_1$ is the episode's percentage of the F-bombs from Roy Kent\n    - $x_2$ is the IMDB rating categorization of the episode\n    \n        - 0 = IMDB rating < 8.5\n        - 1 = IMDB rating $\\ge$ 8.5\n    \n## Odds Ratios  \n\n- Recall the binary logistic regression model,\n\n$$ \\ln \\left( \\frac{\\pi}{1-\\pi} \\right) = \\beta_0 + \\beta_1 x_1 + ... + \\beta_k x_k, $$\n\n- We are modeling the log odds, which are not intuitive with interpretations.\n\n- To be able to discuss the odds, we will \"undo\" the natural log by exponentiation. \n\n- i.e., if we want to interpret the slope for $x_i$, we will look at $e^{\\hat{\\beta}_i}$.\n\n- When interpreting $\\hat{\\beta}_i$, it is an additive effect on the log odds. \n\n- When interpreting $e^{\\hat{\\beta}_i}$, it is a multiplicative effect on the odds.\n\n## Odds Ratios  \n\n- Why is it a multiplicative effect?\n\n$$\n\\begin{align*}\n  \\ln \\left( \\frac{\\pi}{1-\\pi} \\right) &= \\beta_0 + \\beta_1 x_1 + ... + \\beta_k x_k \\\\\n  \\exp\\left\\{ \\ln \\left( \\frac{\\pi}{1-\\pi} \\right) \\right\\} &= \\exp\\left\\{ \\beta_0 + \\beta_1 x_1 + ... + \\beta_k x_k \\right\\} \\\\\n  \\frac{\\pi}{1-\\pi}  &= e^{\\beta_0} e^{\\beta_1 x_1} \\cdots e^{\\beta_k x_k}\n\\end{align*}\n$$\n\n## Odds Ratios  \n\n- Odds ratios:\n\n    - For a 1 [unit of predictor] increase in [predictor name], the odds of [outcome] are multiplied by  [$e^{\\hat{\\beta}_i}$]. \n    - For a 1 [unit of predictor] increase in [predictor name], the odds of [outcome] are [increased or decreased] by [100(e$^{\\hat{\\beta}_i}$-1)\\% or 100(1-e$^{\\hat{\\beta}_i}$)\\%]. \n\n- Compared to linear regression:\n\n    - For a [$k$] [units of predictor] increase in [predictor], we expect [outcome] to [increase or decrease] by [$k \\times |\\hat{\\beta}_1|$] [units of outcome].\n\n## Example: Roy Kent's F-Bombs  \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nround(exp(coefficients(m1)),2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)      F_perc        IMDB \n       0.17        1.03        1.46 \n```\n\n\n:::\n:::\n\n\n\n- Let's interpret the odds ratios:\n\n    - For a 1 percentage point increase in the percentage of f-bombs that came from Roy Kent, the odds of Roy and Keeley dating increase by 3%.\n    \n    - As compared to when episodes have less than an IMDB rating of 8.5, the odds of Roy and Keeley dating are 46% higher in episodes with an IMDB rating of at least 8.5.\n\n    \n## Test for Significant Predictors  \n\n- What we've learned so far re: significance of predictors holds true with logistic regression.\n\n- Looking at the results from `summary()`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = dating ~ F_perc + IMDB, family = binomial(link = \"logit\"), \n    data = richmondway)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)\n(Intercept) -1.76166    1.08995  -1.616    0.106\nF_perc       0.03323    0.02506   1.326    0.185\nIMDB         0.37986    0.72250   0.526    0.599\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 46.662  on 33  degrees of freedom\nResidual deviance: 44.261  on 31  degrees of freedom\nAIC: 50.261\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n\n\n## Test for Significant Predictors  \n\n- **Hypotheses**\n\n    - $H_0: \\ \\beta_{\\text{perc}} = 0$ \n    - $H_1: \\ \\beta_{\\text{perc}} \\ne 0$\n\n- **Test Statistic and *p*-Value**\n\n    - $z_0 = 1.326$\n    - $p = 0.185$\n\n- **Rejection Region**\n\n    - Reject $H_0$ if $p<\\alpha$; $\\alpha=0.05$.\n    \n- **Conclusion / Interpretation**\n\n    - Fail to reject $H_0$. There is not sufficient evidence to suggest there exists a relationship between Roy and Keeley dating and the percentage of f-bombs by Roy.\n    \n## Test for Significant Predictors  \n\n- **Hypotheses**\n\n    - $H_0: \\ \\beta_{\\text{IMDB}} = 0$ \n    - $H_1: \\ \\beta_{\\text{IMDB}} \\ne 0$\n\n- **Test Statistic and *p*-Value**\n\n    - $z_0 = 0.526$\n    - $p = 0.599$\n\n- **Rejection Region**\n\n    - Reject $H_0$ if $p<\\alpha$; $\\alpha=0.05$.\n    \n- **Conclusion / Interpretation**\n\n    - Fail to reject $H_0$. There is not sufficient evidence to suggest there exists a relationship between Roy and Keeley dating and the IMDB rating.\\\n    \n## Test for Significant Regression Line  \n\n- We will take a different approach when testing for a significant regression line.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull <- glm(outcome ~ predictor_1 + predictor_2 + ... + predictor_k, data = dataset_name, family = \"binomial\"(link=\"logit\"))\nreduced <- glm(outcome ~ 1, data = dataset_name, family = \"binomial\"(link=\"logit\")) \nanova(reduced, full, test = \"LRT\")\n```\n:::\n\n\n\n## Test for Significant Regression Line\n\n- **Hypotheses**\n\n    - $H_0: \\ \\beta_1 = \\beta_2 = ... = \\beta_k = 0$ \n    - $H_1:$ at least one $\\beta_i \\ne 0$\n\n- **Test Statistic**\n\n    - $\\chi^2_0 =$ from R\n\n- ***p*-Value**\n\n    - $p = P[\\chi^2_{k-1} \\ge |\\chi^2_0|]$\n\n- **Rejection Region**\n\n    - Reject $H_0$ if $p<\\alpha$.\n    \n## Test for Significant Regression Line\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull <- glm(dating ~ F_perc + IMDB, data = richmondway, family = \"binomial\"(link=\"logit\"))\nreduced <- glm(dating ~ 1, data = richmondway, family = \"binomial\"(link=\"logit\")) # intercept only model\nanova(reduced, full, test = \"LRT\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Resid. Df\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Resid. Dev\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Df\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Deviance\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Pr(>Chi)\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"33\",\"2\":\"46.66233\",\"3\":\"NA\",\"4\":\"NA\",\"5\":\"NA\",\"_rn_\":\"1\"},{\"1\":\"31\",\"2\":\"44.26079\",\"3\":\"2\",\"4\":\"2.401543\",\"5\":\"0.3009619\",\"_rn_\":\"2\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n## Test for Significant Regression Line\n\n- **Hypotheses**\n\n    - $H_0: \\ \\beta_{\\text{perc}} = \\beta_{\\text{IMDB}} = 0$ \n    - $H_1:$ at least one $\\beta_i \\ne 0$\n\n- **Test Statistic**\n\n    - $\\chi^2_0 = 2.402$ \n    - $p = 0.301$\n\n- **Rejection Region**\n\n    - Reject $H_0$ if $p<\\alpha$; $\\alpha=0.05$.\n    \n- **Conclusion/Interpretation**\n\n    - Fail to reject $H_0$. There is not sufficient evidence to suggest that either predictor has a non-zero slope.\n\n## Wrap Up\n\n- That's it for new material for our course.\n\n- The rest of our class meetings will be devoted to working on the project.\n\n    - Remember that the OUR Symposium is on April 17!\n    \n- **It is crucial that you are present in class.**    ",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}